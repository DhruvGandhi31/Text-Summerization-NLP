<!-- # Text-Summerization-NLP

## Workflow

1. update config.yaml
2. update params.yaml
3. update enitty
4. update the configuration manager in src config
5. update the components
6. update the pipeline
7. update the main.py
8. update the app.py -->

# Text-Summerization-NLP

The Text-Summerization.ipynb is an implementation of text summarization using the Pegasus model with the Transformers library.

**Dataset**: SAMSum 

    @article{gliwa2019samsum,
    title={SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization},
    author={Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander},
    journal={arXiv preprint arXiv:1911.12237},
    year={2019}
    }

**Model**: Pegasus

    @misc{zhang2019pegasus,
        title={PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization},
        author={Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter J. Liu},
        year={2019},
        eprint={1912.08777},
        archivePrefix={arXiv},
        primaryClass={cs.CL}
    }

# How to run?
### STEPS:

Clone the repository

```bash
https://github.com/DhruvGandhi31/Text-Summerization-NLP
```
### STEP 01- Create a conda environment after opening the repository

```bash
conda create -n summary python=3.8 -y
```

```bash
conda activate summary
```


### STEP 02- install the requirements
```bash
pip install -r requirements.txt
```


```bash
# Finally run the following command
python app.py
```

Now,
```bash
open up you local host and port
```

# AWS-CICD-Deployment-with-Github-Actions

## 1. Login to AWS console.

## 2. Create IAM user for deployment

	#with specific access

	1. EC2 access : It is virtual machine

	2. ECR: Elastic Container registry to save your docker image in aws


	#Description: About the deployment

	1. Build docker image of the source code

	2. Push your docker image to ECR

	3. Launch Your EC2 

	4. Pull Your image from ECR in EC2

	5. Lauch your docker image in EC2

	#Policy:

	1. AmazonEC2ContainerRegistryFullAccess

	2. AmazonEC2FullAccess

	
## 3. Create ECR repo to store/save docker image
    <!-- - Save the URI: 851725573858.dkr.ecr.eu-north-1.amazonaws.com/text-s -->

	
## 4. Create EC2 machine (Ubuntu) 

## 5. Open EC2 and Install docker in EC2 Machine:
	
	
	#optinal

	sudo apt-get update -y

	sudo apt-get upgrade
	
	#required

	curl -fsSL https://get.docker.com -o get-docker.sh

	sudo sh get-docker.sh

	sudo usermod -aG docker ubuntu

	newgrp docker
	
# 6. Configure EC2 as self-hosted runner:
    setting>actions>runner>new self hosted runner> choose os> then run command one by one


# 7. Setup github secrets:

    AWS_ACCESS_KEY_ID=

    AWS_SECRET_ACCESS_KEY=

    AWS_REGION = us-east-1

    AWS_ECR_LOGIN_URI = demo>>  566373416292.dkr.ecr.ap-south-1.amazonaws.com

    ECR_REPOSITORY_NAME = simple-app

<!-- ## Implementation:


1. Loading Data and Preprocessing: The code downloads a dataset from GitHub and preprocesses it for training the model.

2. Model Setup: It loads the pre-trained Pegasus model and tokenizer from the Hugging Face model hub. 

3. Training: It defines training arguments and trains the Pegasus model on the preprocessed dataset using the Trainer class from the Transformers library.

4. Evaluation: After training, it evaluates the trained model's performance on a test dataset using the ROUGE metric, which measures the quality of summaries generated by comparing them with reference summaries.

5. Saving Model and Tokenizer: Once training and evaluation are complete, the code saves the trained model and tokenizer for future use.

6. Prediction: Finally, it uses the trained model to generate summaries for sample dialogues from the test dataset and compares them with the reference summaries. -->

<!-- ## Future work
The goal is to deploy this model on AWS using Amazon EC2. Containerize the application using Docker.  Set up an API endpoint using AWS API Gateway to provide a standardized interface for interacting with the model. Develop a UI to interact with summarization model.    -->

<!-- ## References

<a id="1">[1]</a> 
SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization
Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander
arXiv preprint arXiv:1911.12237 -->
